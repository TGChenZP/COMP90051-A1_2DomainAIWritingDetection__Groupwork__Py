{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data and feature select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from collections import defaultdict as dd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "from scipy.sparse import save_npz, load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "with open('../data/raw/comp90051-2024s1-project-1/domain1_train_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data1.append(json.loads(line))\n",
    "\n",
    "data2 = []\n",
    "with open('../data/raw/comp90051-2024s1-project-1/domain2_train_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data2.append(json.loads(line))\n",
    "\n",
    "data_test = []\n",
    "with open('../data/raw/comp90051-2024s1-project-1/test_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data_test.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 'Baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Train Val Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create domain labels for data\n",
    "for i in range(len(data1)):\n",
    "    data1[i]['domain'] = 1\n",
    "for i in range(len(data2)):\n",
    "    data2[i]['domain'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Val Test Split\n",
    "\n",
    "# get labels for stratification\n",
    "label1 = [instance['label'] for instance in data1]\n",
    "label2 = [instance['label'] for instance in data2]\n",
    "\n",
    "train_ix_1, val_test_ix_1 = train_test_split(range(len(data1)), test_size=0.3, random_state=SEED, stratify = label1)\n",
    "train_ix_2, val_test_ix_2 = train_test_split(range(len(data2)), test_size=0.3, random_state=SEED, stratify = label2)\n",
    "val_ix_1, test_ix_1 = train_test_split(val_test_ix_1, test_size=0.5, random_state=SEED, stratify = [data1[i]['label'] for i in val_test_ix_1])\n",
    "val_ix_2, test_ix_2 = train_test_split(val_test_ix_2, test_size=0.5, random_state=SEED, stratify = [data2[i]['label'] for i in val_test_ix_2])\n",
    "\n",
    "# split data according to the index from train_test_split\n",
    "train_data_1 = [data1[i] for i in train_ix_1]\n",
    "val_data_1 = [data1[i] for i in val_ix_1]\n",
    "test_data_1 = [data1[i] for i in test_ix_1]\n",
    "train_data_2 = [data2[i] for i in train_ix_2]\n",
    "val_data_2 = [data2[i] for i in val_ix_2]\n",
    "test_data_2 = [data2[i] for i in test_ix_2]\n",
    "\n",
    "# combine the data\n",
    "train_data = train_data_1 + train_data_2\n",
    "val_data = val_data_1 + val_data_2\n",
    "test_data = test_data_1 + test_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text, label, domain and id for each split\n",
    "train_text = [' '.join([str(encode) for encode in instance['text']]) for instance in train_data]\n",
    "val_text = [' '.join([str(encode) for encode in instance['text']]) for instance in val_data]\n",
    "test_text = [' '.join([str(encode) for encode in instance['text']]) for instance in test_data]\n",
    "future_text = [' '.join([str(encode) for encode in instance['text']]) for instance in data_test]\n",
    "\n",
    "train_label = [instance['label'] for instance in train_data]\n",
    "val_label = [instance['label'] for instance in val_data]\n",
    "test_label = [instance['label'] for instance in test_data]\n",
    "\n",
    "train_domain = [instance['domain'] for instance in train_data]\n",
    "val_domain = [instance['domain'] for instance in val_data]\n",
    "test_domain = [instance['domain'] for instance in test_data]\n",
    "\n",
    "train_id = list(range(len(train_data)))\n",
    "val_id = list(range(len(val_data)))\n",
    "test_id = list(range(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF\n",
    "TFIDF = TfidfVectorizer(max_features=83581) # from EDA\n",
    "\n",
    "TFIDF.fit(train_text)\n",
    "train_tfidf = TFIDF.transform(train_text)\n",
    "val_tfidf = TFIDF.transform(val_text)\n",
    "test_tfidf = TFIDF.transform(test_text)\n",
    "future_tfidf = TFIDF.transform(future_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "BoW = CountVectorizer(max_features=83581) # from EDA\n",
    "\n",
    "BoW.fit(train_text)\n",
    "train_bow = BoW.transform(train_text)\n",
    "val_bow = BoW.transform(val_text)\n",
    "test_bow = BoW.transform(test_text)\n",
    "future_bow = BoW.transform(future_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output\n",
    "save_npz(\"../data/curated/baseline/train_tfidf_x.npz\", train_tfidf)\n",
    "save_npz(\"../data/curated/baseline/val_tfidf_x.npz\", val_tfidf)\n",
    "save_npz(\"../data/curated/baseline/test_tfidf_x.npz\", test_tfidf)\n",
    "save_npz('../data/curated/baseline/future_tfidf_x.npz', future_tfidf)\n",
    "\n",
    "save_npz(\"../data/curated/baseline/train_bow_x.npz\", train_bow)\n",
    "save_npz(\"../data/curated/baseline/val_bow_x.npz\", val_bow)\n",
    "save_npz(\"../data/curated/baseline/test_bow_x.npz\", test_bow)\n",
    "save_npz('../data/curated/baseline/future_bow_x.npz', future_bow)\n",
    "\n",
    "with open(\"../data/curated/baseline/train_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_label, f)\n",
    "with open(\"../data/curated/baseline/val_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_label, f)\n",
    "with open(\"../data/curated/baseline/test_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_label, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, gap:int=0):\n",
    "\n",
    "    \"\"\"\n",
    "        Gets sequential feature importance of model and returns it in a list format\n",
    "\n",
    "        Input:\n",
    "            - model: model which has been fitted - must have feature_importances_ and feature_names_in_ attributes\n",
    "            - gap: int - how many features to include in each iteration\n",
    "    \"\"\"\n",
    "\n",
    "    ordered_feature_importance = {}\n",
    "\n",
    "    feature_importance = list(model.feature_importances_)\n",
    "    feature_importance_list = [(i, feature_importance[i]) for i in range(len(feature_importance))]\n",
    "    feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    feature_importance_list = [x for x in feature_importance_list if x[1] > 0]\n",
    "\n",
    "    curr = []\n",
    "    score = 0\n",
    "    for i in tqdm(range(len(feature_importance_list))):\n",
    "\n",
    "        curr.append(feature_importance_list[i][0])\n",
    "        score += feature_importance_list[i][1]\n",
    "\n",
    "\n",
    "        if (i+1) % gap == 0:\n",
    "            ordered_feature_importance[tuple(curr)] = score\n",
    "    \n",
    "    if (i+1) % gap != 0: # account for last combo (if it doesn't fit into the gap)\n",
    "        ordered_feature_importance[tuple(curr)] = score\n",
    "\n",
    "    return ordered_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 924/924 [00:00<00:00, 209194.48it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_xgb = XGBClassifier(max_depth = 12, \n",
    "                            random_state = SEED, \n",
    "                            n_estimators = 100,\n",
    "                            colsample_bytree = 0.75,\n",
    "                            subsample = 0.75\n",
    "                            )\n",
    "\n",
    "tfidf_xgb.fit(train_tfidf, train_label)\n",
    "\n",
    "xgb_tfidf_feature_importance_ordering = get_feature_importance(tfidf_xgb, 10) \n",
    "\n",
    "# export\n",
    "with open(f'../models/xgb_tfidf_feature_importance_ordering_{EXPERIMENT}.pickle', 'wb') as f:\n",
    "    pickle.dump(xgb_tfidf_feature_importance_ordering, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1126/1126 [00:00<00:00, 767433.59it/s]\n"
     ]
    }
   ],
   "source": [
    "bow_xgb = XGBClassifier(max_depth = 12, \n",
    "                            random_state = SEED, \n",
    "                            n_estimators = 100,\n",
    "                            colsample_bytree = 0.75,\n",
    "                            subsample = 0.75\n",
    "                            )\n",
    "\n",
    "bow_xgb.fit(train_bow, train_label)\n",
    "\n",
    "xgb_bow_feature_importance_ordering = get_feature_importance(bow_xgb, 10) \n",
    "\n",
    "# export\n",
    "with open(f'../models/xgb_bow_feature_importance_ordering_{EXPERIMENT}.pickle', 'wb') as f:\n",
    "    pickle.dump(xgb_bow_feature_importance_ordering, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inference 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9996825396825397 0.9992852037169406 0.9992857142857143\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8688888888888889 0.6685393258426966 0.7710714285714286\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.87 0.6666666666666666 0.7682142857142857\n"
     ]
    }
   ],
   "source": [
    "with open('../models/tmp_models/jiaochengb_lgbc_xgb_tfidf_Baseline.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('../models/xgb_tfidf_feature_importance_ordering_Baseline.pickle', 'rb') as f:\n",
    "    feature_importance_ordering = pickle.load(f)\n",
    "\n",
    "print(accuracy_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[86]])), \n",
    "      f1_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[86]]), average='binary'), \n",
    "    balanced_accuracy_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[86]])))\n",
    "print(accuracy_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[86]])), \n",
    "      f1_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[86]]), average='binary'), \n",
    "    balanced_accuracy_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[86]])))\n",
    "print(accuracy_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[86]])), \n",
    "      f1_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[86]]), average='binary'),\n",
    "    balanced_accuracy_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[86]])))\n",
    "\n",
    "future_predict = clf.predict(future_tfidf[:, list(feature_importance_ordering.keys())[86]])\n",
    "predictions = pd.DataFrame({'id': range(len(future_predict)), 'class': future_predict})\n",
    "predictions.to_csv('../predictions/jiaochengb_lgbc_xgb_tfidf_Baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/COMP90051/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "1.0 1.0 1.0\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8618518518518519 0.6510757717492984 0.7611904761904762\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8614814814814815 0.638996138996139 0.7508333333333332\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "with open('../models/tmp_models/jiaochengb-balaccu_lgbc_xgb_tfidf_Baseline.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('../models/xgb_tfidf_feature_importance_ordering_Baseline.pickle', 'rb') as f:\n",
    "    feature_importance_ordering = pickle.load(f)\n",
    "\n",
    "print(accuracy_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[92]])), \n",
    "      f1_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[92]]), average='binary'), \n",
    "    balanced_accuracy_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[92]])))\n",
    "print(accuracy_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[92]])), \n",
    "      f1_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[92]]), average='binary'), \n",
    "    balanced_accuracy_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[92]])))\n",
    "print(accuracy_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[92]])), \n",
    "      f1_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[92]]), average='binary'),\n",
    "    balanced_accuracy_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[92]])))\n",
    "\n",
    "future_predict = clf.predict(future_tfidf[:, list(feature_importance_ordering.keys())[92]])\n",
    "predictions = pd.DataFrame({'id': range(len(future_predict)), 'class': future_predict})\n",
    "predictions.to_csv('../predictions/jiaochengb-balaccu_lgbc_xgb_tfidf_Baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/COMP90051/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "1.0 1.0 1.0\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8629629629629629 0.6469465648854962 0.756547619047619\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8622222222222222 0.6381322957198443 0.7495238095238095\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "with open('../models/tmp_models/jiaochengb-f1_lgbc_xgb_tfidf_Baseline.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('../models/xgb_tfidf_feature_importance_ordering_Baseline.pickle', 'rb') as f:\n",
    "    feature_importance_ordering = pickle.load(f)\n",
    "\n",
    "print(accuracy_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[83]])), \n",
    "      f1_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[83]]), average='binary'), \n",
    "    balanced_accuracy_score(train_label, clf.predict(train_tfidf[:, list(feature_importance_ordering.keys())[83]])))\n",
    "print(accuracy_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[83]])), \n",
    "      f1_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[83]]), average='binary'), \n",
    "    balanced_accuracy_score(val_label, clf.predict(val_tfidf[:, list(feature_importance_ordering.keys())[83]])))\n",
    "print(accuracy_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[83]])), \n",
    "      f1_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[83]]), average='binary'),\n",
    "    balanced_accuracy_score(test_label, clf.predict(test_tfidf[:, list(feature_importance_ordering.keys())[83]])))\n",
    "\n",
    "future_predict = clf.predict(future_tfidf[:, list(feature_importance_ordering.keys())[83]])\n",
    "predictions = pd.DataFrame({'id': range(len(future_predict)), 'class': future_predict})\n",
    "predictions.to_csv('../predictions/jiaochengb-f1_lgbc_xgb_tfidf_Baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: warnings\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.7746666666666666 0.6202898550724638 0.6974782608695652 0.7657142857142858\n",
      "0.7786666666666666 0.6114975845410628 0.6950821256038647 0.7653571428571428\n"
     ]
    }
   ],
   "source": [
    "with open('../models/tmp_models/jiaochengb-balaccu_lgbc_xgb_tfidf_Baseline.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "# with open('../models/xgb_tfidf_feature_importance_ordering_Baseline.pickle', 'rb') as f:\n",
    "#     feature_importance_ordering = pickle.load(f)\n",
    "\n",
    "val_pred = clf.predict(val_tfidf)\n",
    "test_pred = clf.predict(test_tfidf)\n",
    "\n",
    "val_dom1_pred = [val_pred[i] for i in range(len(val_pred)) if val_domain[i] == 1]\n",
    "val_dom2_pred = [val_pred[i] for i in range(len(val_pred)) if val_domain[i] == 2]\n",
    "val_dom1_true = [val_label[i] for i in range(len(val_label)) if val_domain[i] == 1]\n",
    "val_dom2_true = [val_label[i] for i in range(len(val_label)) if val_domain[i] == 2]\n",
    "\n",
    "test_dom1_pred = [test_pred[i] for i in range(len(test_pred)) if test_domain[i] == 1]\n",
    "test_dom2_pred = [test_pred[i] for i in range(len(test_pred)) if test_domain[i] == 2]\n",
    "test_dom1_true = [test_label[i] for i in range(len(test_label)) if test_domain[i] == 1]\n",
    "test_dom2_true = [test_label[i] for i in range(len(test_label)) if test_domain[i] == 2]\n",
    "\n",
    "\n",
    "print(balanced_accuracy_score(val_dom1_true, val_dom1_pred), balanced_accuracy_score(val_dom2_true, val_dom2_pred), \\\n",
    "      (balanced_accuracy_score(val_dom1_true, val_dom1_pred) + balanced_accuracy_score(val_dom2_true, val_dom2_pred)) / 2, balanced_accuracy_score(val_label, val_pred))\n",
    "print(balanced_accuracy_score(test_dom1_true, test_dom1_pred), balanced_accuracy_score(test_dom2_true, test_dom2_pred), \\\n",
    "        (balanced_accuracy_score(test_dom1_true, test_dom1_pred) + balanced_accuracy_score(test_dom2_true, test_dom2_pred)) / 2, balanced_accuracy_score(test_label, test_pred))\n",
    "\n",
    "# future_predict = clf.predict(future_tfidf)\n",
    "# predictions = pd.DataFrame({'id': range(len(future_predict)), 'class': future_predict})\n",
    "# predictions.to_csv('../predictions/jiaochengb-balaccu_lgbc_xgb_tfidf_Baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP90051",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
