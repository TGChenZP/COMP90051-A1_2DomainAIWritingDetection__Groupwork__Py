{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "with open('../data/raw/comp90051-2024s1-project-1/domain1_train_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data1.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = []\n",
    "with open('../data/raw/comp90051-2024s1-project-1/domain2_train_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data2.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data: 5000 13000\n"
     ]
    }
   ],
   "source": [
    "print('length of data:', len(data1), len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique symbols: 83581\n",
      "min and max value of \"tokens\": 1 83581\n"
     ]
    }
   ],
   "source": [
    "# number of unique words, and their min max value\n",
    "all_symbols = set()\n",
    "for i in range(len(data1)):\n",
    "    all_symbols.update(set(data1[i]['text']))\n",
    "for j in range(len(data2)):\n",
    "    all_symbols.update(set(data2[j]['text']))\n",
    "print('number of unique symbols:', len(all_symbols))\n",
    "all_symbols_list = list(all_symbols)\n",
    "all_symbols_list.sort()\n",
    "print('min and max value of \"tokens\":', all_symbols_list[0], all_symbols_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens in all sentences: 4341949\n",
      "average length of sentence: 241.2193888888889\n"
     ]
    }
   ],
   "source": [
    "# total length of tokens\n",
    "total_length = 0\n",
    "for i in range(len(data1)):\n",
    "    total_length += len(data1[i]['text'])\n",
    "for j in range(len(data2)):\n",
    "    total_length += len(data2[j]['text'])\n",
    "print('total tokens in all sentences:', total_length)\n",
    "print('average length of sentence:', total_length / (len(data1) + len(data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP90051",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
